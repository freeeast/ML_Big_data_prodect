{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dba0970-78bd-4eda-827b-9ba3ea223d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b331f",
   "metadata": {},
   "source": [
    "## Read the CSV file and pre-process the data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9dafb2b-cebf-4009-8ce5-923d09869bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text\n",
       "0  aba decides against community broadcasting lic...\n",
       "1     act fire witnesses must be aware of defamation\n",
       "2     a g calls for infrastructure protection summit\n",
       "3           air nz staff in aust strike for pay rise\n",
       "4      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"abcnews-date-text.csv\", on_bad_lines='skip', usecols=[\"headline_text\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23396312-2817-41e3-976e-79714c6e85e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1244184 entries, 0 to 1244183\n",
      "Data columns (total 1 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   headline_text  1244184 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be433008-c049-4f34-b8dd-33d30ff61df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116298</th>\n",
       "      <td>10 killed in pakistan bus crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57967</th>\n",
       "      <td>10 killed in pakistan bus crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911080</th>\n",
       "      <td>110 with barry nicholls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672958</th>\n",
       "      <td>110 with barry nicholls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748629</th>\n",
       "      <td>110 with barry nicholls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676423</th>\n",
       "      <td>110 with barry nicholls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897042</th>\n",
       "      <td>110 with barry nicholls episode 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826828</th>\n",
       "      <td>110 with barry nicholls episode 15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             headline_text\n",
       "116298     10 killed in pakistan bus crash\n",
       "57967      10 killed in pakistan bus crash\n",
       "911080             110 with barry nicholls\n",
       "672958             110 with barry nicholls\n",
       "748629             110 with barry nicholls\n",
       "676423             110 with barry nicholls\n",
       "897042  110 with barry nicholls episode 15\n",
       "826828  110 with barry nicholls episode 15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['headline_text'].duplicated(keep=False)].sort_values('headline_text').head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "067be118-302a-41b6-8916-930340d154ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates('headline_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f710f829",
   "metadata": {},
   "source": [
    "## Preparing data for vectorizaion ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace8a28",
   "metadata": {},
   "source": [
    "TF-IDF\n",
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf-idf value increases proportionally to the number of times a word appears in the document and is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general. Nowadays, tf-idf is one of the most popular term-weighting schemes; 83% of text-based recommender systems in the domain of digital libraries use tf-idf.\n",
    "\n",
    "Variations of the tf–idf weighting scheme are often used by search engines as a central tool in scoring and ranking a document's relevance given a user query. tf–idf can be successfully used for stop-words filtering in various subject fields, including text summarization and classification.\n",
    "\n",
    "One of the simplest ranking functions is computed by summing the tf–idf for each query term; many more sophisticated ranking functions are variants of this simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e633698",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}',\"%\"]\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(punc)\n",
    "desc = data['headline_text'].values\n",
    "vectorizer = TfidfVectorizer(stop_words = stop_words)\n",
    "X = vectorizer.fit_transform(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ab576",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = vectorizer.get_feature_names()\n",
    "print(len(word_features))\n",
    "print(word_features[5000:5100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8cb15",
   "metadata": {},
   "source": [
    "### Tokenlizion ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec9dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z\\']+')\n",
    "\n",
    "def tokenize(text):\n",
    "    return [stemmer.stem(word) for word in tokenizer.tokenize(text.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e224494",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer(stop_words = stop_words, tokenizer = tokenize)\n",
    "X2 = vectorizer2.fit_transform(desc)\n",
    "word_features2 = vectorizer2.get_feature_names()\n",
    "print(len(word_features2))\n",
    "print(word_features2[:50]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0662b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer3 = TfidfVectorizer(stop_words = stop_words, tokenizer = tokenize, max_features = 1000)\n",
    "X3 = vectorizer3.fit_transform(desc)\n",
    "words = vectorizer3.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ea75ad",
   "metadata": {},
   "source": [
    "## Cluster Part ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aefbad",
   "metadata": {},
   "source": [
    "Elbow method to select number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "for i in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=i,init='k-means++',max_iter=300,n_init=10,random_state=0)\n",
    "    kmeans.fit(X3)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1,11),wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.savefig('elbow.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46975d",
   "metadata": {},
   "source": [
    "### 3 Cluster ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b0e247-14af-4f1d-a46a-d48505d6b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 3, n_init = 20, n_jobs = 1) # n_init(number of iterations for clsutering) n_jobs(number of cpu cores to use)\n",
    "kmeans.fit(X3)\n",
    "# We look at 3 the clusters generated by k-means.\n",
    "common_words = kmeans.cluster_centers_.argsort()[:,-1:-26:-1]\n",
    "for num, centroid in enumerate(common_words):\n",
    "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6204016",
   "metadata": {},
   "source": [
    "### 5 Cluster ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ec9a1-736b-40bb-bcb9-8467e5e6eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 5, n_init = 20, n_jobs = 1)\n",
    "kmeans.fit(X3)\n",
    "# We look at 5 the clusters generated by k-means.\n",
    "common_words = kmeans.cluster_centers_.argsort()[:,-1:-26:-1]\n",
    "for num, centroid in enumerate(common_words):\n",
    "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7248e",
   "metadata": {},
   "source": [
    "### 6 Cluster ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc65f91-4fab-43b1-ae56-8096c90174b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 6, n_init = 20, n_jobs = 1)\n",
    "kmeans.fit(X3)\n",
    "# We look at 6 the clusters generated by k-means.\n",
    "common_words = kmeans.cluster_centers_.argsort()[:,-1:-26:-1]\n",
    "for num, centroid in enumerate(common_words):\n",
    "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18db5ce1",
   "metadata": {},
   "source": [
    "### 8 Cluster ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8357db-7657-40db-ab0d-edfd528e0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 8, n_init = 20, n_jobs = 1)\n",
    "kmeans.fit(X3)\n",
    "# Finally, we look at 8 the clusters generated by k-means.\n",
    "common_words = kmeans.cluster_centers_.argsort()[:,-1:-26:-1]\n",
    "for num, centroid in enumerate(common_words):\n",
    "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
